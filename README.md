# Эксперимент: приблеженное вычисление координат станций метро, базируясь на времени ходьбы до них из базы объявлений о продаже/аренде недвижимости

С помощью `Selenium` (для скраппинга через браузер, самый рабочий вариант), `BeautifulSoup` и `REST API` (для скраппинга через внутренний api, нестабильный вариант) программа скачивает объявления из заданного поиска (ссылка вида https://www.cian.ru/kupit-kvartiru-1-komn-ili-2-komn/), сохраняет их в `SQLite` и затем анализирует используя `Pandas`, `GeoPandas` и `NetworkX`, строя визуализацию на карте и веб интерфейс с помощью `Streamlit`.

Проект временно запущен по адресу http://84.252.133.125:8080

## Инструкция по запуску (для Linux):

Для начала установите `Docker` на вашу систему и запустите в нем этот контейнер:
```
docker build . -t hse_underground_approx
docker run -p 8080:8080 -v /dev/shm:/dev/shm -v ${PWD}/data:/app/data -it hse_underground_approx
```
Теперь вы можете открыть `streamlit` интерфейс в браузере по ссылке http://localhost:8080/ (если docker запущен на той же машине)

## Критерии оценки

| Критерий | Что есть в проекте |
| ----------- | ----------- |
| Обработка данных с помощью pandas. | Хранение и генерация списка данных, файлы `src/cian/database.py` (функция `CianDatabase.select`) и `src/utils.py` (функция `find_lines`). Вся работа с `GeoPandas` так же является работой с `Pandas`, много в файле `src/utils.py` |
| Веб-скреппинг | Используется `BeautifulSoup` + `js2py` для скреппинга по rest, и `Selenium` для скреппинга через браузер. Файлы `src/cian/scrap_rest.py` и `src/cian/scrap_browser.py` |
| Работа с REST API (XML/JSON) | Скреппинг сайта с объявлениями, файл `src/cian/scrap_rest.py`, функция `CianRest._get_page_offers` |
| Визуализация данных | Визуализация собранных и обработанных данных на карте используя `Streamlit` и `pydeck` |
| Streamlit | Используется, файл `src/main.py` |
| SQL | Используется для хранения объявлений, файл `src/cian/database.py` |
| Регулярные выражения (для решения задач, для которых трудно придумать простое решение без регулярных выражений) | Простой парсинг html тега, файл `src/cian/proxy/scrapper.py`, строка 29, функция `_get_proxy_list` |
| Работа с графами (библиотека networkx) | Используется для поиска приблеженной связи (наличие пути) между разными станциями одной линии метро, файл `src/utils.py`, функция `find_lines` |
| Объём (осмысленных строк кода) | `pygount` насчитал около 500 строк, осмысленных точно сильно больше 120 |
| Целостность проекта | На усмотрение рецензента |
| Общее впечатление | На усмотрение рецензента |